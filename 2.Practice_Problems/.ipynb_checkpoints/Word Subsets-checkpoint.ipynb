{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13a0202",
   "metadata": {},
   "source": [
    "# Word Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b1ff3",
   "metadata": {},
   "source": [
    "You are given two string arrays words1 and words2.\n",
    "\n",
    "A string b is a subset of string a if every letter in b occurs in a including multiplicity.\n",
    "\n",
    "For example, \"wrr\" is a subset of \"warrior\" but is not a subset of \"world\".\n",
    "A string a from words1 is universal if for every string b in words2, b is a subset of a.\n",
    "\n",
    "Return an array of all the universal strings in words1. You may return the answer in any order.\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "Input: words1 = [\"amazon\",\"apple\",\"facebook\",\"google\",\"leetcode\"], words2 = [\"e\",\"o\"]\n",
    "Output: [\"facebook\",\"google\",\"leetcode\"]\n",
    "\n",
    "**Example 2:**\n",
    "\n",
    "Input: words1 = [\"amazon\",\"apple\",\"facebook\",\"google\",\"leetcode\"], words2 = [\"l\",\"e\"]\n",
    "Output: [\"apple\",\"google\",\"leetcode\"]\n",
    " \n",
    "**Constraints:**\n",
    "\n",
    "- 1 <= words1.length, words2.length <= 104\n",
    "- 1 <= words1[i].length, words2[i].length <= 10\n",
    "- words1[i] and words2[i] consist only of lowercase English letters.\n",
    "- All the strings of words1 are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c52c75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['facebook', 'google', 'leetcode']\n",
      "['apple', 'google', 'leetcode']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def words_subsets(words1, words2):\n",
    "    # Step 1: Compute the maximum frequency of each character needed\n",
    "    def max_freq_count(words):\n",
    "        max_freq = Counter()\n",
    "        for word in words:\n",
    "            word_count = Counter(word)\n",
    "            for char, count in word_count.items():\n",
    "                max_freq[char] = max(max_freq[char], count)\n",
    "        return max_freq\n",
    "    \n",
    "    # Calculate the required character frequencies from words2\n",
    "    required_freq = max_freq_count(words2)\n",
    "    \n",
    "    # Step 2: Check which words in words1 are universal\n",
    "    def is_universal(word, required_freq):\n",
    "        word_count = Counter(word)\n",
    "        for char, count in required_freq.items():\n",
    "            if word_count[char] < count:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    # Collect all universal words\n",
    "    universal_words = [word for word in words1 if is_universal(word, required_freq)]\n",
    "    \n",
    "    return universal_words\n",
    "\n",
    "# Example usage:\n",
    "words1 = [\"amazon\", \"apple\", \"facebook\", \"google\", \"leetcode\"]\n",
    "words2 = [\"e\", \"o\"]\n",
    "print(words_subsets(words1, words2))  # Output: [\"facebook\", \"google\", \"leetcode\"]\n",
    "\n",
    "words2 = [\"l\", \"e\"]\n",
    "print(words_subsets(words1, words2))  # Output: [\"apple\", \"google\", \"leetcode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53196c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
