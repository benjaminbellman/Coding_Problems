{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768b176a",
   "metadata": {},
   "source": [
    "# Word Ladder II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de09b4",
   "metadata": {},
   "source": [
    "A transformation sequence from word beginWord to word endWord using a dictionary wordList is a sequence of words beginWord -> s1 -> s2 -> ... -> sk such that:\n",
    "\n",
    "Every adjacent pair of words differs by a single letter.\n",
    "Every si for 1 <= i <= k is in wordList. Note that beginWord does not need to be in wordList.\n",
    "sk == endWord\n",
    "Given two words, beginWord and endWord, and a dictionary wordList, return all the shortest transformation sequences from beginWord to endWord, or an empty list if no such sequence exists. Each sequence should be returned as a list of the words [beginWord, s1, s2, ..., sk].\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "Input: beginWord = \"hit\", endWord = \"cog\", wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n",
    "Output: [[\"hit\",\"hot\",\"dot\",\"dog\",\"cog\"],[\"hit\",\"hot\",\"lot\",\"log\",\"cog\"]]\n",
    "Explanation: There are 2 shortest transformation sequences:\n",
    "\"hit\" -> \"hot\" -> \"dot\" -> \"dog\" -> \"cog\"\n",
    "\"hit\" -> \"hot\" -> \"lot\" -> \"log\" -> \"cog\"\n",
    "\n",
    "**Example 2:**\n",
    "\n",
    "Input: beginWord = \"hit\", endWord = \"cog\", wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\"]\n",
    "Output: []\n",
    "Explanation: The endWord \"cog\" is not in wordList, therefore there is no valid transformation sequence.\n",
    " \n",
    "**Constraints:**\n",
    "\n",
    "- 1 <= beginWord.length <= 5\n",
    "- endWord.length == beginWord.length\n",
    "- 1 <= wordList.length <= 500\n",
    "- wordList[i].length == beginWord.length\n",
    "- beginWord, endWord, and wordList[i] consist of lowercase English letters.\n",
    "- beginWord != endWord\n",
    "- All the words in wordList are unique.\n",
    "- The sum of all shortest transformation sequences does not exceed 105."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f19626a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15656/1979575622.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeque\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mfindLadders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeginWord\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendWord\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwordList\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mwordSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mendWord\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwordSet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from collections import deque, defaultdict\n",
    "\n",
    "def findLadders(beginWord: str, endWord: str, wordList: list[str]) -> list[list[str]]:\n",
    "    wordSet = set(wordList)\n",
    "    if endWord not in wordSet:\n",
    "        return []\n",
    "\n",
    "    # BFS: build parent links only for nodes on *shortest* paths to endWord\n",
    "    parents = defaultdict(list)   # child -> list of parents\n",
    "    q = deque([beginWord])\n",
    "    found = False\n",
    "    visited = set([beginWord])\n",
    "\n",
    "    while q and not found:\n",
    "        level_visited = set()\n",
    "        for _ in range(len(q)):\n",
    "            word = q.popleft()\n",
    "            # generate neighbors by changing one letter\n",
    "            word_chars = list(word)\n",
    "            for i in range(len(word_chars)):\n",
    "                orig = word_chars[i]\n",
    "                for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "                    if c == orig: \n",
    "                        continue\n",
    "                    word_chars[i] = c\n",
    "                    nxt = \"\".join(word_chars)\n",
    "                    if nxt in wordSet:\n",
    "                        if nxt not in visited:\n",
    "                            if nxt not in level_visited:\n",
    "                                q.append(nxt)\n",
    "                                level_visited.add(nxt)\n",
    "                            parents[nxt].append(word)\n",
    "                            if nxt == endWord:\n",
    "                                found = True\n",
    "                word_chars[i] = orig\n",
    "        visited.update(level_visited)\n",
    "        # optional pruning: once a level is processed, remove it from wordSet to keep graph minimal\n",
    "        wordSet -= visited\n",
    "\n",
    "    if not found:\n",
    "        return []\n",
    "\n",
    "    # Backtrack all paths from endWord to beginWord using the parents map\n",
    "    res = []\n",
    "    path = [endWord]\n",
    "\n",
    "    def dfs(word):\n",
    "        if word == beginWord:\n",
    "            res.append(path[::-1])\n",
    "            return\n",
    "        for p in parents[word]:\n",
    "            path.append(p)\n",
    "            dfs(p)\n",
    "            path.pop()\n",
    "\n",
    "    dfs(endWord)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f92b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
